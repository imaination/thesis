{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last edited/used: 5/11/2023\n",
    "\n",
    "#Purpose: look at performances of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1712972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from scipy.stats import chisquare\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "font = {'family' : 'Helvetica',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f5bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrics & functions\n",
    "\n",
    "def mda(df):\n",
    "    mda = 0\n",
    "    for idx in range(len(df)):\n",
    "        if df['binary_pred'].iloc[idx] == df['TrueLabel'].iloc[idx]:\n",
    "            mda += 1\n",
    "    mda = mda / len(df)\n",
    "    return round(mda, 4)\n",
    "\n",
    "\n",
    "def get_net_profit(df):\n",
    "    net = 0\n",
    "    for idx in range(len(df)):\n",
    "        if df['binary_pred'].iloc[idx] == df['TrueLabel'].iloc[idx]:\n",
    "            net += df['Profit'].iloc[idx]\n",
    "        else:\n",
    "            net += -df['Profit'].iloc[idx]\n",
    "    return round(net, 2)\n",
    "\n",
    "\n",
    "def get_binary_prediction(forecasted, threshold=0.5):\n",
    "    binary_pred = []\n",
    "#     for predicted in forecasted.iloc[:,0]:\n",
    "    for predicted in forecasted:\n",
    "        if predicted > threshold:\n",
    "            binary_pred.append(1)\n",
    "        else:\n",
    "            binary_pred.append(0)\n",
    "    return {'binary_pred':binary_pred}\n",
    "\n",
    "\n",
    "def get_profit_thr_df(predictions, profits, image_type):\n",
    "    thresh = list(np.arange(0.0, 1.0, 0.001))\n",
    "    net_profit_list = []\n",
    "    \n",
    "    max_net = -100.00\n",
    "    max_net_thresh = 0.0\n",
    "    for thr in thresh:\n",
    "        pred_dict = get_binary_prediction(predictions, threshold=thr)\n",
    "        df = pd.DataFrame.from_dict(pred_dict)\n",
    "        df = pd.concat([df, profit_], axis=1)\n",
    "        net = get_net_profit(df)\n",
    "        net_profit_list.append(net)\n",
    "        if net > max_net:\n",
    "            max_net = net\n",
    "            max_net_thresh = thr\n",
    "    \n",
    "    return max_net, max_net_thresh, net_profit_list\n",
    "\n",
    "def get_log_return(df):\n",
    "    logs = []\n",
    "    for idx in range(len(df)):\n",
    "        pt = df['FutureValue'].iloc[idx]\n",
    "        pt_1 = df['CurrentValue'].iloc[idx]\n",
    "        if df['binary_pred'].iloc[idx] == 0: # if long (buy)\n",
    "#             print(pt, pt_1)\n",
    "            gross_return = pt / pt_1\n",
    "#             print('gross return', gross_return)\n",
    "        else: # if short (sell)\n",
    "            gross_return = pt_1 / pt\n",
    "#             print('gross return for short', gross_return)\n",
    "        logs.append(np.log(gross_return))\n",
    "    return np.array(logs)\n",
    "\n",
    "# It is custom for the risk free return to use the 10 Year Treasury Note,\n",
    "# but as it has been low for long time, often 0 is used.\n",
    "\n",
    "# https://www.bankrate.com/banking/savings/bank-of-america-savings-rates/\n",
    "# bank of america savings interest rate = 0.01% \n",
    "def sharpe_ratio(log_returns, interst_rate = 0):\n",
    "#     https://www.learnpythonwithrune.org/how-to-calculate-sharpe-ratio-with-pandas-and-numpy/\n",
    "    # visualize the log-return of the portfolio\n",
    "    fig, ax = plt.subplots()\n",
    "    log_df = pd.DataFrame(log_returns)\n",
    "    log_df.hist(bins=50, ax=ax)\n",
    "    # daily sharpe ratio\n",
    "    sharpe_ratio = (log_returns.mean() - interst_rate) / log_returns.std()\n",
    "    # annualized sharpe ratio\n",
    "    asr = sharpe_ratio*252**.5\n",
    "    \n",
    "    return sharpe_ratio, asr\n",
    "\n",
    "\n",
    "def get_confusion(df):\n",
    "     ### Confusion Matrix\n",
    "    ConfusionMatrixDisplay.from_predictions(df['TrueLabel'][:], df['binary_pred'][:])\n",
    "    tn, fp, fn, tp = confusion_matrix(df['TrueLabel'][:], df['binary_pred'][:]).ravel()\n",
    "    print('tn: {}, fp: {}, fn: {}, tp: {}'.format(tn, fp, fn, tp))\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = tp/(tp+fn)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = tn/(tn+fp) \n",
    "\n",
    "    # Overall accuracy\n",
    "    ACC = (tp+tn)/(tp+fp+fn+tn)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    sr, asr = sharpe_ratio(get_log_return(df))\n",
    "    \n",
    "    return TPR, TNR, ACC, sr, asr\n",
    "\n",
    "\n",
    "def get_chi_square(df):\n",
    "    # Statistical Test: Chi-Squared Statistics \n",
    "    # Used to determine whether the confusion matrix of a classifier \n",
    "    # is statistically significant, or merely white noise\n",
    "\n",
    "    # A chi-square test is a statistical test usedÂ to compare observed results with expected results. \n",
    "    # The purpose of this test is to determine if a difference between observed data and expected data \n",
    "    # is due to chance, or if it is due to a relationship between the variables you are studying.\n",
    "\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html\n",
    "    # Calculate a one-way chi-square test.\n",
    "    # The chi-square test tests the null hypothesis that the categorical data has the given frequencies.\n",
    "    # By setting axis=None, the test is applied to all data in the array, which is equivalent to applying the test to the flattened array.\n",
    "\n",
    "    observed = [df['binary_pred'].values.tolist().count(0), df['binary_pred'].values.tolist().count(1)]\n",
    "    expected = [df['TrueLabel'].values.tolist().count(0), df['TrueLabel'].values.tolist().count(1)]\n",
    "    print('observed: ',observed)\n",
    "    print('expected: ', expected)\n",
    "    print(chisquare(observed, expected))\n",
    "    \n",
    "    \n",
    "# def evaluate_results(prediction, horizon, profit, THRESH):\n",
    "def evaluate_results(prediction, profit, THRESH):\n",
    "    predictions = prediction\n",
    "#     predictions = prediction[[\"predicted\"]]\n",
    "    # Drop Index\n",
    "    profit_ = profit.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Set threshold to compare with true labels\n",
    "    pred_dict = get_binary_prediction(predictions, threshold=THRESH) # POSITION \n",
    "    df = pd.DataFrame.from_dict(pred_dict)\n",
    "    df['TrueLabel'] = profit_['TrueLabel']\n",
    "    df['FutureValue'] = profit_['FutureValue']\n",
    "    df['CurrentValue'] = profit_['CurrentValue']\n",
    "    df['Profit'] = profit_['Profit']\n",
    "    \n",
    "    ### Confusion Matrix\n",
    "    TPR, TNR, ACC, sr, asr = get_confusion(df)\n",
    "    \n",
    "    # Results\n",
    "    print(\"Net Profit: \", get_net_profit(df))\n",
    "    print(\"MDA: \", mda(df)*100)\n",
    "    print(\"True Positive Rate :\", TPR*100)\n",
    "    print(\"True Negative Rate :\", TNR*100)\n",
    "    print(\"Accuracy :\", ACC)\n",
    "    print(\"Sharpe Ratio :\", sr)\n",
    "    print(\"Annualized Sharpe Ratio :\", asr)\n",
    "    \n",
    "    get_chi_square(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data here\n",
    "\n",
    "#POSITION\n",
    "# horizon = 'POSITION'\n",
    "# horizon = 'SWING'\n",
    "horizon = 'SCALP'\n",
    "\n",
    "# {'LONG': 0, 'SHORT': 1}\n",
    "if horizon == \"SWING\":\n",
    "    vote = [0] #LONG (SWING)\n",
    "    profit_from = '2018-04-07 00:00:00'\n",
    "elif horizon == \"POSITION\":\n",
    "    vote = [1] #SHORT\n",
    "    profit_from = '2018-04-15 00:00:00'\n",
    "elif horizon == \"SCALP\":\n",
    "    vote = [1] #SHORT (POSITION, SCALP)\n",
    "    profit_from = '2018-03-23 08:00:00'\n",
    "    \n",
    "    \n",
    "# get profit chart from test date -> \n",
    "# 2018_04_15_00_00_00 # POSITION\n",
    "# 2018_04_07_00_00_00 # SWING\n",
    "# 2018_04_07_00_00_00 # SCALP\n",
    "\n",
    "\n",
    "# test = pd.read_csv('../data/results_POSITION/true_pred_ARIMA_POSITION_1D.csv')\n",
    "arima = pd.read_csv('../data/results_{0}/true_pred_ARIMA_{0}_1D.csv'.format(horizon))\n",
    "cnn1d = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_1D_1D.csv'.format(horizon))\n",
    "gaf = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_GAF.csv'.format(horizon))\n",
    "gaf_agg = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_GAF_AGG.csv'.format(horizon))\n",
    "cs = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_CS.csv'.format(horizon))\n",
    "ti = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_TI.csv'.format(horizon))\n",
    "gaf_ST = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_ST_GAF.csv'.format(horizon))\n",
    "gaf_agg_ST = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_ST_GAF_AGG.csv'.format(horizon))\n",
    "cs_ST = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_ST_CS.csv'.format(horizon))\n",
    "ti_ST = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_ST_TI.csv'.format(horizon))\n",
    "\n",
    "\n",
    "# gaf_cut = pd.read_csv('../data/results_{0}/true_pred_2dCNN_{0}_CUT_GAF.csv'.format(horizon))\n",
    "\n",
    "# Load Profit Chart\n",
    "profit_chart = pd.read_csv('../data/{}_profit_chart.csv'.format(horizon))[[\"PredictionDate\", \"CurrentValue\", \"FutureValue\", \"TrueLabel\", \"Profit\"]]\n",
    "\n",
    "# observed:  [16, 204]\n",
    "# expected:  [127, 93]\n",
    "\n",
    "# chisquare([2000, 400], [1400, 1000])\n",
    "\n",
    "# normalize predictions of 2D CNN\n",
    "predictions_arima = minmax_scale(arima[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_cnn1d = minmax_scale(cnn1d[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_gaf = minmax_scale(gaf[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_gaf_agg = minmax_scale(gaf_agg[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_cs = minmax_scale(cs[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_ti = minmax_scale(ti[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_gaf_ST = minmax_scale(gaf_ST[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_gaf_agg_ST = minmax_scale(gaf_agg_ST[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_cs_ST = minmax_scale(cs_ST[[\"predicted\"]], feature_range=(0,1))\n",
    "predictions_ti_ST = minmax_scale(ti_ST[[\"predicted\"]], feature_range=(0,1))\n",
    "\n",
    "# predictions_gaf = minmax_scale(gaf_cut[[\"predicted\"]], feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Prediction Frequency\n",
    "\n",
    "# Prediction Frequency Histograms\n",
    "fig, axs = plt.subplots(5, 2, figsize=(20,17))\n",
    "axs[0, 0].hist(predictions_arima, bins=20)\n",
    "axs[0, 0].set_title('ARIMA')\n",
    "axs[0, 1].hist(predictions_cnn1d, bins=20)\n",
    "axs[0, 1].set_title('1D CNN')\n",
    "axs[1, 0].hist(predictions_gaf, bins=20)\n",
    "axs[1, 0].set_title('GAF')\n",
    "axs[1, 1].hist(predictions_gaf_agg, bins=20)\n",
    "axs[1, 1].set_title('GAF AGG')\n",
    "axs[2, 0].hist(predictions_cs, bins=20)\n",
    "axs[2, 0].set_title('CS')\n",
    "axs[2, 1].hist(predictions_ti, bins=20)\n",
    "axs[2, 1].set_title('TI')\n",
    "axs[3, 0].hist(predictions_gaf_ST, bins=20)\n",
    "axs[3, 0].set_title('GAF ST')\n",
    "axs[3, 1].hist(predictions_gaf_agg_ST, bins=20)\n",
    "axs[3, 1].set_title('GAF AGG ST')\n",
    "axs[4, 0].hist(predictions_cs_ST, bins=20)\n",
    "axs[4, 0].set_title('CS ST')\n",
    "axs[4, 1].hist(predictions_ti_ST, bins=20)\n",
    "axs[4, 1].set_title('TI ST')\n",
    "\n",
    "# fig.suptitle('Prdiction Frequency', fontsize=12)\n",
    "# for ax in axs.flat:\n",
    "#     ax.set(xlabel='predictions', ylabel='frequency')\n",
    "\n",
    "# # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()\n",
    "\n",
    "fig.savefig('./{}_prediction_freq.png'.format(horizon),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Choose threshold with a subset of test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of test data\n",
    "\n",
    "mask = (profit_chart.PredictionDate >= profit_from) & (profit_chart.PredictionDate  < '2019')\n",
    "profit_ = profit_chart.loc[mask]\n",
    "profit_ = profit_.reset_index(drop=True)\n",
    "\n",
    "profit_evaluate = profit_chart[profit_chart.PredictionDate >= '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e334ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net Profit by threshold\n",
    "# Profits by Thresholds on a Subset of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true labels for threshold test subset\n",
    "true_0 = list(profit_.TrueLabel).count(0)\n",
    "true_1 = list(profit_.TrueLabel).count(1)\n",
    "print('number of labels 0, 1:', true_0, true_1)\n",
    "print('total number of test set:', len(profit_))\n",
    "\n",
    "\n",
    "# true labels for evaluation test subset\n",
    "true_0_eval = list(profit_evaluate.TrueLabel).count(0)\n",
    "true_1_eval = list(profit_evaluate.TrueLabel).count(1)\n",
    "print('number of labels 0, 1:', true_0_eval, true_1_eval)\n",
    "print('total number of test set:', len(profit_evaluate))\n",
    "\n",
    "# profit_ = profit_[profit_['PredictionDate'] < '2019-01-01 00:00:00']\n",
    "# majority vote (set up here)\n",
    "# majority_vote = pd.DataFrame(majority_vote * len(profit_), columns=['binary_pred'])\n",
    "# majority_vote.head()\n",
    "majority_vote = vote * len(profit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8013925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get profits of each model to determine threshold\n",
    "\n",
    "arima_max_net, arima_max_net_thresh, arima_lst = get_profit_thr_df(predictions_arima[:len(profit_)], profit_, 'arima')\n",
    "cnn1dmax_net, cnn1d_max_net_thresh, cnn1d_lst = get_profit_thr_df(predictions_cnn1d[:len(profit_)], profit_, 'cnn1d')\n",
    "gaf_max_net, gaf_max_net_thresh, gaf_lst = get_profit_thr_df(predictions_gaf[:len(profit_)], profit_, 'gaf')\n",
    "gaf_agg_max_net, gaf_agg_max_net_thresh, gaf_agg_lst = get_profit_thr_df(predictions_gaf_agg[:len(profit_)], profit_, 'gaf_agg')\n",
    "cs_max_net, cs_max_net_thresh, cs_lst = get_profit_thr_df(predictions_cs[:len(profit_)], profit_, 'CS')\n",
    "ti_max_net, ti_max_net_thresh, ti_lst = get_profit_thr_df(predictions_ti[:len(profit_)], profit_, 'TI')\n",
    "gaf_ST_max_net, gaf_ST_max_net_thresh, gaf_ST_lst = get_profit_thr_df(predictions_gaf_ST[:len(profit_)], profit_, 'gaf_ST')\n",
    "gaf_agg_ST_max_net, gaf_agg_ST_max_net_thresh, gaf_agg_ST_lst = get_profit_thr_df(predictions_gaf_agg_ST[:len(profit_)], profit_, 'gaf_agg_ST')\n",
    "cs_ST_max_net, cs_ST_max_net_thresh, cs_ST_lst = get_profit_thr_df(predictions_cs_ST[:len(profit_)], profit_, 'CS_ST')\n",
    "ti_ST_max_net, ti_ST_max_net_thresh, ti_ST_lst = get_profit_thr_df(predictions_ti_ST[:len(profit_)], profit_, 'TI_ST')\n",
    "mv_max_net, mv_max_net_thresh, mv_lst = get_profit_thr_df(majority_vote, profit_, 'mv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshes = [arima_max_net_thresh, cnn1d_max_net_thresh, gaf_max_net_thresh, gaf_agg_max_net_thresh, cs_max_net_thresh,\n",
    "           ti_max_net_thresh, gaf_ST_max_net_thresh, gaf_agg_ST_max_net_thresh, cs_ST_max_net_thresh, ti_ST_max_net_thresh,\n",
    "           mv_max_net_thresh]\n",
    "\n",
    "nets = [arima_max_net, cnn1dmax_net, gaf_max_net, gaf_agg_max_net, cs_max_net, ti_max_net, gaf_ST_max_net, gaf_agg_ST_max_net,\n",
    "       cs_ST_max_net, ti_ST_max_net, mv_max_net]\n",
    "\n",
    "models = ['arima', 'cnn1d', 'gaf', 'gaf_agg', 'cs', 'ti', 'gaf_ST', 'gaf_agg_ST',\n",
    "       'cs_ST', 'ti_ST', 'majority vote']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6a0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_thr_df = pd.DataFrame({'arima': arima_lst, 'cnn1d':cnn1d_lst, 'gaf': gaf_lst, 'gaf_agg':gaf_agg_lst,\n",
    "                             'cs': cs_lst, 'ti': ti_lst, 'majority': mv_lst}, index=list(np.arange(0.0, 1.0, 0.001)))\n",
    "\n",
    "lines = profit_thr_df.plot.line(title='Profit by Threshold', xlabel='Threshold', ylabel='Net Profit')\n",
    "lines.figure.savefig('./{}_profit_thresh_1.png'.format(horizon),bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8baf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_thr_df = pd.DataFrame({'arima': arima_lst, 'cnn1d':cnn1d_lst, 'gaf_ST': gaf_ST_lst, 'gaf_agg_ST':gaf_agg_ST_lst,\n",
    "                             'cs_ST': cs_ST_lst, 'ti_ST': ti_ST_lst, 'majority': mv_lst}, index=list(np.arange(0.0, 1.0, 0.001)))\n",
    "\n",
    "lines = profit_thr_df.plot.line(title='Profit by Threshold', xlabel='Threshold', ylabel='Net Profit')\n",
    "lines.figure.savefig('./{}_profit_thresh_2.png'.format(horizon),bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max net profit possible\n",
    "round(sum(profit_evaluate['Profit']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3203ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(threshes)):\n",
    "    print('{} threshold:'.format(models[i]), threshes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_results(vote * len(profit_evaluate), profit_evaluate, mv_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_results(cs_ST['predicted'][len(profit_):], profit_evaluate, cs_ST_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_evaluate['Profit_logged'] = np.log(profit_evaluate['Profit'] + 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c976c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profit_evaluate['Profit'], bins=20)\n",
    "\n",
    "plt.xlabel('Profits')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Profit Frequency for {}'.format(horizon))\n",
    "plt.savefig('./{}_profit_dist.png'.format(horizon),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(profit_evaluate['Profit_logged'], bins=20)\n",
    "\n",
    "plt.xlabel('Logged Profits')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Profit Frequency for {}'.format(horizon))\n",
    "plt.savefig('./{}_logged_profit_dist.png'.format(horizon),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dfaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_logged = np.median(profit_evaluate['Profit_logged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17906fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_std = np.var(profit_evaluate['Profit_logged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_cutoff = med_logged - one_std\n",
    "upper_cutoff = med_logged + one_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef168f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce015044",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - 1 is low\n",
    "print('low: ', len(profit_evaluate[profit_evaluate['Profit_logged'] < lower_cutoff]))\n",
    "\n",
    "# 1 - 3 is mid\n",
    "mask_cutoff = (profit_evaluate.Profit_logged >= lower_cutoff) & (profit_evaluate.Profit_logged  <= upper_cutoff)\n",
    "print('mid: ', len(profit_evaluate[mask_cutoff]))\n",
    "\n",
    "# greater than 3 is high\n",
    "print('high: ', len(profit_evaluate[profit_evaluate['Profit_logged'] > upper_cutoff]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_segments(profit_evaluate):\n",
    "    profit_segments = []\n",
    "    df = profit_evaluate.copy()\n",
    "    med_logged = np.median(df['Profit_logged'])\n",
    "    one_std = np.var(df['Profit_logged'])\n",
    "    lower_cutoff = med_logged - one_std\n",
    "    upper_cutoff = -2.0 #med_logged + one_std\n",
    "    \n",
    "    for profit in df['Profit_logged']:\n",
    "        if profit < lower_cutoff:\n",
    "            segment = 'low'\n",
    "        elif profit > upper_cutoff:\n",
    "            segment = 'high'\n",
    "        else:\n",
    "            segment = 'mid'\n",
    "\n",
    "        profit_segments.append(segment)\n",
    "    \n",
    "    print('low: ', profit_segments.count('low'))\n",
    "    print('mid: ', profit_segments.count('mid'))\n",
    "    print('high: ', profit_segments.count('high'))\n",
    "    df[\"segments\"] = profit_segments\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79412f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_seg = get_profit_segments(profit_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c15982",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1213f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_segments(profit, predicted, THRESH):\n",
    "\n",
    "    correct = []\n",
    "    wrong = []\n",
    "#     predicted_labels = get_binary_prediction(arima['predicted'][len(profit_):], threshold=0.7)\n",
    "    predicted_labels = get_binary_prediction(predicted, threshold=THRESH)\n",
    "    eval_ =  profit.reset_index(drop=True)\n",
    "\n",
    "    for i in range(len(eval_)):\n",
    "        # have to choose a threshold first and change predicted from probability to labels\n",
    "        if eval_['TrueLabel'].iloc[i] == predicted_labels['binary_pred'][i]:\n",
    "            correct.append(eval_['segments'].iloc[i])\n",
    "        else:\n",
    "            wrong.append(eval_['segments'].iloc[i])\n",
    "            \n",
    "    dict_segments = {'correct':correct, 'wrong':wrong}\n",
    "    high_seg = dict_segments['correct'].count('high') / (dict_segments['correct'].count('high') + dict_segments['wrong'].count('high'))\n",
    "    mid_seg = dict_segments['correct'].count('mid') / (dict_segments['correct'].count('mid') + dict_segments['wrong'].count('mid'))\n",
    "    low_seg = dict_segments['correct'].count('low') / (dict_segments['correct'].count('low') + dict_segments['wrong'].count('low'))\n",
    "    \n",
    "    print('Proportion Classified Correctly for each segment\\n')\n",
    "    print('high: ', round(high_seg,4))\n",
    "    print('mid: ', round(mid_seg,4))\n",
    "    print('low: ', round(low_seg,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, arima['predicted'][len(profit_):], arima_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f662de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, cnn1d['predicted'][len(profit_):], cnn1d_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98809ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, gaf['predicted'][len(profit_):], gaf_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea282ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, gaf_agg['predicted'][len(profit_):], gaf_agg_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda782bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, cs['predicted'][len(profit_):], cs_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, ti['predicted'][len(profit_):], ti_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942932e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, gaf_ST['predicted'][len(profit_):], gaf_ST_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140fdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, gaf_agg_ST['predicted'][len(profit_):], gaf_agg_ST_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, cs_ST['predicted'][len(profit_):], cs_ST_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_segments(with_seg, ti_ST['predicted'][len(profit_):], ti_ST_max_net_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98436c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(profit_evaluate[profit_evaluate.TrueLabel == 1].Profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(profit_evaluate[profit_evaluate.TrueLabel == 0].Profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c32069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Statistical Test: Comparisons of Models using Accuracy CI test\n",
    "\n",
    "# # Assume given two models f1 and f2, w/ estimated accuracies a1 \n",
    "# # (estimated on test set with size n1) and a2 (estimated on test set with size n2)\n",
    "# # Conclude accuracy f1 > f2 or accuracy f1 â accracy f2 > 0 , if CI for a1-a2 is entirely to the right of 0\n",
    "# # If interval contains 0, no difference\n",
    "\n",
    "# # alpha = 0.05, two-sided Z = 1.96\n",
    "# ci_lower = (a1 - a2) - 1.96*np.sqrt(((a1*(1-a1))/n1) + ((a2*(1-a2))/n2))\n",
    "# ci_upper = (a1 - a2) + 1.96*np.sqrt(((a1*(1-a1))/n1) + ((a2*(1-a2))/n2))\n",
    "\n",
    "# print(\"CI interval :\", ci_lower, ci_upper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
